# ISA 1: entering, importing, summarizing and subsetting data {#sec-ISACh1}

## R outcomes

After reading this chapter, you can: 

1. Enter new data 
2. Import and work with existing data 
3. Create frequency tables 
4. Select subsets of data using `dplyr::filter`

## Required packages

You will need the following additional packages:

-   `dplyr` (but we will simply install the `tidyverse` collection so that we also have the pipe operator - `%>%` - loaded)
-   `haven`

```{r}
#| label: install_load
#| message: FALSE 
#| warning: FALSE

library(tidyverse)
library(haven)

```

## First, create a project! {#sec-makeproj}

Follow the [instructions in Chapter 1 of this book](1_r_markdown_basics.qmd#sec-newproj) to create a new R project where you can store all of your ISA scripts, assignments, and datasets. Opening an R Studio session with the newly-created project icon will set the project folder as your home directory, meaning that - if you store all the course datasets here - loading datasets can be performed smoothly without having to enter long directory pathnames to point R to the file you want to load.   

## Entering data

We will work almost exclusively with dataframes on this course. These are essentially tables, where rows correspond to observations on the *unit of analysis* (e.g., mice, people, countries), and columns correspond to variables (e.g., fur colour, occupation, GDP per capita).

Let's create a new dataframe of student names and ages:

```{r}
#| label: gospels

students<-data.frame(names = c("Matthew","Mark","Luke","John"), age = c(18,19,18,20))

```

Above, we assigned a dataframe to the name `students` with the `<-` operator (an alternative to "=" - which also works - used by R). We then told R that we wanted to create a dataframe with variables `names` and `age`, and we provided some values to both of those variables. Here, the `c()` is used to concatenate individual entries into a column vector.

To see our new dataframe in all of its glory, we can simply type its name at the console:

```{r}
#| label: revelation

students
```

If we only want to show a particular variable from the frame, then we type the name of the dataframe and the name of the variable we want to see, separated by the `$` operator:

```{r}
#| label: ages

students$age
```

## Measures of central tendency

In this course, we will consider three measures of central tendency.

### The arithmetic mean

This is usually represented by one of two formulae:

(@)  $\bar{x} = \frac{1}{n} \sum\limits_{i = 1}^{n}x_i$


(@)  $\bar{x} = \frac{\sum_{i = 1}^{n}x_i}{n}$


Straightforwardly: sum all scores and divide by the total number of scores. In R, the arithmetic mean is given by the `mean` function:

```{r mean}

mean(students$age)

```

Strictly speaking, the mean can only be sensibly calculated for interval/ratio level data. 

### The median

This is the 50th percentile in the dataset (i.e., it divides the data into a lower half and an upper half). It is obtained by ranking scores and finding the value which divides the dataset in two. 

For data $x$ with $n$ elements:

* if $n$ is **odd**, $med(x) = x_{(n+1)/2}$
  

* if $n$ is **even**, $med(x) = \frac{x_{(n/2)} + x_{((n/2)+1)}}{2}$

For example, in a sorted dataset with 11 values, the median will be the value at the observation ranked 6th. However, in a sorted dataset with 12 values, the median will be the arithmetic mean of the values ranked in 6th and 7th. In R, we can simply use `median`:

```{r median}

median(students$age)

```

The median can be used to summarize both interval/ratio and ordinal variables.

### The mode

Lastly, we turn to the mode, which is simply the most frequently occurring value. At the time of writing, base R doesn't have a function to compute the mode, so we have prepared one which you can load with the file "customFunctions" which is available on [Canvas](canvas.uva.nl). To load the function, you need to use the `source` command as follows:

```{r source}

source("customFunctions")

```

**Note that the above will only work if you have the "customFunctions" file saved in your current working directory**. We recommend that you save all relevant datasets and files into the project folder which you - hopefully - [already created](5_r_ISA1.qmd#sec-makeproj). If the file exists in another folder, then you have to give R the path to the file, like so:

```{r sourcepath, eval = FALSE}

source("./folder_where_I_put_stuff/customFunctions")

```

Once added, we can run the function `cusmode`, which provides the mode and its frequency.

```{r modefun}

cusmode(students$age)

```

Datasets can have multiple modes; for example, let's imagine a new student joins the party:

```{r Billy}

students[5,1]<-"Billy"
students[5,2]<-20

cusmode(students$age)

```

The mode can be calculated for all measurement levels about which you have learned, but it is typically most informative when there are relatively few values which the data can take.

## Importing existing data

We will now import some data from the [European Social Survey](https://www.europeansocialsurvey.org/). The data is saved as .sav, which is a file format native to the SPSS software. We use this as it contains informative labels describing the variables, but the ESS data is also available in .csv and other formats.

Ensure that you have the ESS data saved to your project folder and then run the following:

```{r ESSload, eval = FALSE}

ESS<-haven::read_sav("ESS11.sav")

```

```{r ESSloadreal, echo = FALSE}
ESS<-haven::read_sav("C:/Users/David/OneDrive - UvA/2025_2026/ISA_24_25/Datasets/ESS11.sav")
```

Running the `dplyr::glimpse` command will give us a quick look at the dataset, along with telling us the number of rows (human survey respondents) and columns (variables).

## Summarizing data

### Frequency tables

Frequency give us information about how often each unique value of a variable occurs. In R, we can use the base `table` function to show us the frequency distribution of respondents' `agea`.

```{r ESSage}

table(ESS$agea)

```

This is a little difficult to see in the above output, but the first row shows the unique values of `agea`, while the second row gives the corresponding frequency. To make things a little more readable, let's use some `dplyr` functions.

```{r ESStidyage}

ESS %>%
  dplyr::group_by(agea) %>% # <1>
  dplyr::summarize("Frequency" = dplyr::n()) %>% # <2>
  knitr::kable(align = "c") # <3>
  

```

1. Pass ESS into into `dplyr::group_by`, where we request for the data to be organized by the unique values of `agea`.
2. We use `dplyr::summarize` to reduce ESS to two variables: `Age` = the unique age values in the dataset; `Frequency` is the occurence count for each age value. `dplyr::n()` sums up all instances of a given value of `agea`.
3. We pass the output dataframe to the R Studio built-in `knitr::kable` function for generating tables, and tell it to center-justify the table columns (`align = "c"`).


### Summary descriptive statistics

The base `summary` function gives us an overview of key descriptive statistics. The counts you see for `NA` (see @nte-na) reflect the number of respondents for whom no information about age was recorded.

```{r ESSagesummary}

summary(ESS$agea)

```

You will notice that the mode is missing, so we but we can use another custom function called `cussummary` to add this:

```{r ESSagesummary_2}

cussummary(ESS$agea)

```


## Datawrangling skills: selecting subsets

Say we are interested only in the age of respondents from the Netherlands. Using the `dplyr::filter` function, we can pick those out and then summarize the `agea` variable. A useful feature of the .sav version of the ESS dataset is the variable labelling. If you enter `ESS$cntry` into the console, you get a list of the numeric values which code for different countries, but also a list of what those numeric values represent, at the bottom of the console output. However, we will ask `haven` to print only the labels for convenience.  

```{r cntryshow}

haven::print_labels(ESS$cntry)

```

We can see that the Netherlands is represented by the value 17 in the dataset. We could now filter on this number, but it might be more informative if the variable **value** was the same as variable **label**. Thankfully, the `haven` package which we used for the data import makes this easily achievable:

```{r cntrylabel}

ESS <- ESS %>% # <1> 
  dplyr::mutate(cntry_text = haven::as_factor(cntry)) # <2>
  

```

1. Reassign `ESS` so that the operations will be saved to the dataframe.
2. Use `dplyr::mutate` to create the new variable (as it is good practice **NOT** to write over existing variables) and `haven::as_factor(cntry)` to assign the text label of `cntry` to each participant, instead of the numerical value.

Now, we can filter in a more transparent manner:

```{r cntryfilter}

ESS_NL<-ESS %>% # <1>
  dplyr::filter(cntry_text == "Netherlands") # <2>
  

```


1. Take `ESS`
2. Use `dplyr::filter` to select only participants from the Netherlands. `cntry_text == "Netherlands"` asks the function to return only participants with a value on the variable `cntry_text` which is equal to "Netherlands". Note the use of the `==` instead of `=`.

::: {#nte-logoper .callout-note}
### Use of logical operators when subsetting or selecting

You will probably rely mostly on the following: 

1.  `==` - searches for perfect matches, as in the example above.
2.  `!=` - the complement of `==`. E.g, `dplyr::filter(cntry_text != "Netherlands")` means "give me all respondents who are NOT from the Netherlands".
3.  `&` - used when you want the selected responses to satisfy multiple conditions. E.g., `dplyr::filter(cntry_text == "Netherlands" & agea > 22)` means "give me all respondents from the Netherlands **who are also older than (> = "greater than") 22**".
4. `|` - **OR** selection. Use this if you want to select responses which match at least one of the specified conditions. E.g., `dplyr::filter(cntry_text == "Netherlands" | agea > 22)` will return participants who are either in the Netherlands, or older than 22, or both. Participants who meet neither criterion will be filtered out.
:::

Now that we have extracted Dutch respondents' data, we can run create frequency tables and summary lists as previously.

```{r NLfreq}

table(ESS_NL$agea)

```


```{r NLsummary}

cussummary(ESS_NL$agea)

```

While this gives us everything we need, we might wish to have a neater looking summary table. `dplyr` can help us with that:

```{r NLtidysummary}

ESS_NL %>% dplyr::summarize("N respondents" = n(),
                            "Min. age" = min(agea, na.rm = TRUE), 
                            "Q1 age" = quantile(agea, .25, na.rm = TRUE),
                            "Median age" = median(agea, na.rm = TRUE),
                            "Q3 age" = quantile(agea, .75, na.rm = TRUE),
                            "Max. age" = max(agea, na.rm = TRUE),
                            "Mean age" = mean(agea, na.rm = TRUE),
                            "Modal age" = 
                            paste(as.character(cusmode(agea)$mode), collapse = " ") # <1>
                            ) %>% 
  knitr::kable(align = "c") # <2>

```

1. This line helps us create a single text string should we have multiple modes. `as.character` converts input to a text string, and the `paste` function with the added option `collapse = " "` folds the multiple modes into one text string separated by a space.
2. We pass the output dataframe to `knitr::kable` to make our table neater. 

## Summary

In this chapter, we covered:

* Entering new data
* Importing existing data in .sav format
* Calculating frequencies and descriptive statistics
* Using `dplyr::filter` to select subsets of data